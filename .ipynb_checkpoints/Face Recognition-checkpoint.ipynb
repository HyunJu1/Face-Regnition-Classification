{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from six.moves import cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "# Steps_per_epoch should typically be equal to the number of unique samples of your dataset divided by the batch size.\n",
    "steps_per_epoch = int(40000/batch_size)\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = '60102358_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (40000, 32, 32, 3)\n",
      "40000 train samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_data():\n",
    "    # Modify path string. use your path which your dataset is in\n",
    "    path = 'D:\\DeepLearning_Project\\outputs'\n",
    "\n",
    "    fpath = os.path.join(path, 'HJ')\n",
    "    \n",
    "    with open(fpath, 'rb') as f:\n",
    "        d = cPickle.load(f, encoding='bytes')\n",
    "        \n",
    "    X_train = d\n",
    "    y_train = \"HJ\"\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, 32, 32)\n",
    "    X_train = X_train.transpose(0, 2, 3, 1)\n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "x_train, y_train = load_data()\n",
    "\n",
    "# Check your data\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chunghyup/python_workspace/keras_workspace/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/chunghyup/python_workspace/keras_workspace/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.8483 - acc: 0.3517\n",
      "Epoch 2/100\n",
      " 185/1250 [===>..........................] - ETA: 9s - loss: 1.7161 - acc: 0.4071"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5a299c22f563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     workers=4)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Save model and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_workspace/keras_workspace/venv/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_workspace/keras_workspace/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_workspace/keras_workspace/venv/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_workspace/keras_workspace/venv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_workspace/keras_workspace/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_workspace/keras_workspace/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_workspace/keras_workspace/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Train\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
